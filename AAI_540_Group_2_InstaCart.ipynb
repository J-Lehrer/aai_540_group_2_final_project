{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Imj-SZs4qIOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary libraries"
      ],
      "metadata": {
        "id": "uhBrCi3MsbZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "p-MMKTQZsi2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decompressing the \"Archive\" files."
      ],
      "metadata": {
        "id": "7xlQkZa_aeZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNmHwGGeWoVw",
        "outputId": "823b7583-18af-4c7d-bee8-46d298a9301c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted to /content/drive/MyDrive/MLOps/Instant_Cart\n"
          ]
        }
      ],
      "source": [
        "# Defining the path to the \"Archives\" folder.\n",
        "archive_path = \"/content/drive/MyDrive/MLOps/archive.zip\"\n",
        "extract_path =\"/content/drive/MyDrive/MLOps/Instant_Cart\"\n",
        "\n",
        "# Extract the archive\n",
        "with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(f\"Files extracted to {extract_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the extracted CSV files"
      ],
      "metadata": {
        "id": "V5_HpEmUbNVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_path =\"/content/drive/MyDrive/MLOps/Instant_Cart\""
      ],
      "metadata": {
        "id": "M2AC3416voQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the paths to the files\n",
        "orders_path = os.path.join(extract_path, 'orders.csv')\n",
        "order_products_prior_path = os.path.join(extract_path, 'order_products__prior.csv')\n",
        "order_products_train_path = os.path.join(extract_path, 'order_products__train.csv')\n",
        "aisles_path = os.path.join(extract_path, 'aisles.csv')\n",
        "departments_path = os.path.join(extract_path, 'departments.csv')\n",
        "products_path = os.path.join(extract_path, 'products.csv')\n",
        "\n",
        "# Loading the CSV files into DataFrames\n",
        "orders = pd.read_csv(orders_path)\n",
        "order_products_prior = pd.read_csv(order_products_prior_path)\n",
        "order_products_train = pd.read_csv(order_products_train_path)\n",
        "aisles = pd.read_csv(aisles_path)\n",
        "departments = pd.read_csv(departments_path)\n",
        "products = pd.read_csv(products_path)\n",
        "\n",
        "print(\"Files successfully load!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEBu7idUbRDg",
        "outputId": "7e001383-23b2-4bc8-f95a-843b98776674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files successfully load!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Dataframes"
      ],
      "metadata": {
        "id": "k1cLAsPVcabS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking DataFrame shape and info\n",
        "print(\"Orders:\")\n",
        "print(orders.shape)\n",
        "print(orders.info())\n",
        "print(\"\")\n",
        "print(\"Order Products Prior:\")\n",
        "print(order_products_prior.shape)\n",
        "print(order_products_prior.info())\n",
        "print(\"\")\n",
        "print(\"Order Products Train:\")\n",
        "print(order_products_train.shape)\n",
        "print(order_products_train.info())\n",
        "print(\"\")\n",
        "print(\"Aisles:\")\n",
        "print(aisles.shape)\n",
        "print(aisles.info())\n",
        "print(\"\")\n",
        "print(\"Departments:\")\n",
        "print(departments.shape)\n",
        "print(departments.info())\n",
        "print(\"\")\n",
        "print(\"Products:\")\n",
        "print(products.shape)\n",
        "print(products.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYtB1rkacfaV",
        "outputId": "b8948f2e-c401-47ab-9f41-0bc5d427f8b5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orders:\n",
            "(3421083, 7)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3421083 entries, 0 to 3421082\n",
            "Data columns (total 7 columns):\n",
            " #   Column                  Dtype  \n",
            "---  ------                  -----  \n",
            " 0   order_id                int64  \n",
            " 1   user_id                 int64  \n",
            " 2   eval_set                object \n",
            " 3   order_number            int64  \n",
            " 4   order_dow               int64  \n",
            " 5   order_hour_of_day       int64  \n",
            " 6   days_since_prior_order  float64\n",
            "dtypes: float64(1), int64(5), object(1)\n",
            "memory usage: 182.7+ MB\n",
            "None\n",
            "\n",
            "Order Products Prior:\n",
            "(32434489, 4)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32434489 entries, 0 to 32434488\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Dtype\n",
            "---  ------             -----\n",
            " 0   order_id           int64\n",
            " 1   product_id         int64\n",
            " 2   add_to_cart_order  int64\n",
            " 3   reordered          int64\n",
            "dtypes: int64(4)\n",
            "memory usage: 989.8 MB\n",
            "None\n",
            "\n",
            "Order Products Train:\n",
            "(1384617, 4)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1384617 entries, 0 to 1384616\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count    Dtype\n",
            "---  ------             --------------    -----\n",
            " 0   order_id           1384617 non-null  int64\n",
            " 1   product_id         1384617 non-null  int64\n",
            " 2   add_to_cart_order  1384617 non-null  int64\n",
            " 3   reordered          1384617 non-null  int64\n",
            "dtypes: int64(4)\n",
            "memory usage: 42.3 MB\n",
            "None\n",
            "\n",
            "Aisles:\n",
            "(134, 2)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 134 entries, 0 to 133\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   aisle_id  134 non-null    int64 \n",
            " 1   aisle     134 non-null    object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.2+ KB\n",
            "None\n",
            "\n",
            "Departments:\n",
            "(21, 2)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21 entries, 0 to 20\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   department_id  21 non-null     int64 \n",
            " 1   department     21 non-null     object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 468.0+ bytes\n",
            "None\n",
            "\n",
            "Products:\n",
            "(49688, 4)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49688 entries, 0 to 49687\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   product_id     49688 non-null  int64 \n",
            " 1   product_name   49688 non-null  object\n",
            " 2   aisle_id       49688 non-null  int64 \n",
            " 3   department_id  49688 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 1.5+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep"
      ],
      "metadata": {
        "id": "UbHZQ1Amqdf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate product orders"
      ],
      "metadata": {
        "id": "WWBZh-HVeyeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, I am combining the dataset: order_products_prior.csv and order_products_train files to compute the total frequency of each product."
      ],
      "metadata": {
        "id": "7MJgNdA9e4du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining prior and train datasets\n",
        "all_order_products = pd.concat([order_products_prior, order_products_train])\n",
        "\n",
        "# Calculating product frequency\n",
        "product_frequency = all_order_products.groupby('product_id').size().reset_index(name='order_count')\n",
        "\n",
        "# Getting the top 10,000 most ordered products\n",
        "top_10k_products = product_frequency.nlargest(10000, 'order_count')\n",
        "print(\"Top 10,000 products identified!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXLGTwBHe2UB",
        "outputId": "c33b243e-1b3d-4041-85f0-473904154590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10,000 products identified!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering orders by Top 10,000 products"
      ],
      "metadata": {
        "id": "9pBSoe8vgBcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, I am filtering the orders to include only those that contain one or more of the top 10,000 products"
      ],
      "metadata": {
        "id": "MjLzbXiRgHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering orders with top 10k products\n",
        "filtered_orders = all_order_products[all_order_products['product_id'].isin(top_10k_products['product_id'])]\n",
        "\n",
        "# Getting the list of relevant order IDs\n",
        "filtered_order_ids = filtered_orders['order_id'].unique()\n",
        "\n",
        "# Filtering the orders DataFrame\n",
        "filtered_orders_df = orders[orders['order_id'].isin(filtered_order_ids)]\n",
        "print(f\"Filtered orders to include only top 10,000 products. Remaining orders: {len(filtered_orders_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHXlbl_AgOQ6",
        "outputId": "71cf548a-9449-4ce7-e8cc-3ce5fb640660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered orders to include only top 10,000 products. Remaining orders: 3321331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_orders_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljwpuP9Nt_N2",
        "outputId": "6fb7412b-d7fa-4390-d1b2-dcc8f7e0bdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'user_id', 'eval_set', 'order_number', 'order_dow',\n",
            "       'order_hour_of_day', 'days_since_prior_order'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further limiting orders by Size"
      ],
      "metadata": {
        "id": "j0WrEK3Qg6Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous step, the total number of orders were reduced to: 3,321,331. Next, I am further limiting the size by retaining orders with a minimum of (5) items to reduce the dataset size further."
      ],
      "metadata": {
        "id": "Gzy5dC9Lg_QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of items in each order\n",
        "order_item_count = filtered_orders.groupby('order_id').size().reset_index(name='item_count')\n",
        "\n",
        "# Setting the minimum item threshold (e.g., X = 5)\n",
        "X = 5\n",
        "\n",
        "# Filtering orders with at least X items\n",
        "large_orders = order_item_count[order_item_count['item_count'] >= X]\n",
        "\n",
        "# Getting the list of valid order IDs\n",
        "valid_order_ids = large_orders['order_id']\n",
        "\n",
        "# Filtering the original dataset to keep only the valid order IDs\n",
        "filtered_orders_df = filtered_orders[filtered_orders['order_id'].isin(valid_order_ids)]\n",
        "\n",
        "# Counting unique orders in the final filtered dataset\n",
        "unique_orders_count = filtered_orders_df['order_id'].nunique()\n",
        "\n",
        "print(f\"Filtered down to orders with at least {X} items.\")\n",
        "print(f\"Final number of unique orders: {unique_orders_count}\")\n",
        "print(f\"Final number of rows (products): {len(filtered_orders_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOYESoK0oXfR",
        "outputId": "42ee8df4-8f71-4b9b-aa5c-1d6283b9dbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered down to orders with at least 5 items.\n",
            "Final number of unique orders: 2400986\n",
            "Final number of rows (products): 28368235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further limiting order to \"Active Users\""
      ],
      "metadata": {
        "id": "6f5-XkvKiwFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously, I limited the orders to include only those that contain only 5 products from the top 10k products. We ended with a total size of: 2,400,986. For further reducing the dataset, I am going to focus on users with consistent purchasing behavior. For example, users with more than \"Y\" total orders. For accomplishing this step, I am going to count the total number of orders per user and filter users with at least 10 orders."
      ],
      "metadata": {
        "id": "OxFMPMs3i80Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_orders_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6utRJKZtqAz",
        "outputId": "d81a2413-399d-4ded-e5d2-78c542ed28fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging user_id into filtered_orders_df\n",
        "filtered_orders_df = pd.merge(\n",
        "    filtered_orders_df,\n",
        "    orders[['order_id', 'user_id']],\n",
        "    on='order_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Confirming the user_id column is now included\n",
        "print(filtered_orders_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPfnToP9ughg",
        "outputId": "b327315a-d7d0-41fb-820b-8eb48b9e14a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered', 'user_id'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the total number of orders per user\n",
        "user_order_counts = filtered_orders_df.groupby('user_id').size().reset_index(name='order_count')\n",
        "\n",
        "# Setting the threshold for active users (e.g., Y = 10 orders)\n",
        "Y = 10\n",
        "active_users = user_order_counts[user_order_counts['order_count'] >= Y]\n",
        "active_user_ids = active_users['user_id']\n",
        "\n",
        "print(f\"Number of active users with at least {Y} orders: {len(active_user_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZN37tF4jaD7",
        "outputId": "e20cb112-b179-45ee-cd27-5123b8d1734a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of active users with at least 10 orders: 184340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_orders_active_users = filtered_orders_df[filtered_orders_df['user_id'].isin(active_user_ids)]\n",
        "\n",
        "print(f\"Remaining orders: {len(filtered_orders_active_users)}\")\n",
        "print(f\"Unique users: {filtered_orders_active_users['user_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkabOFp9pwa8",
        "outputId": "8fe5a667-4a47-4e0a-970f-d06ccba6b08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining orders: 28313728\n",
            "Unique users: 184340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique orders remaining: {filtered_orders_active_users['order_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Awir8r4rLnh",
        "outputId": "f2a31e76-6065-4b9c-81ea-047994038695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique orders remaining: 2391917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_orders_active_users.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z0vyp2Iu6b6",
        "outputId": "f9d6fca1-74b4-42ad-e559-486c2f700ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered', 'user_id'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving filtered_orders_active_users DataFram into csv\n",
        "filtered_orders_active_users.to_csv('/content/drive/MyDrive/MLOps/Instant_Cart/filtered_orders_active_users.csv', index=False)"
      ],
      "metadata": {
        "id": "c5F_XLsLu_V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further filtering by top 10 aisles or departments."
      ],
      "metadata": {
        "id": "1lUMMyf-qBIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the previous process, we obtained a total of 2,391,917 orders. This time, I am focusing on the most frequently ordered items within the top 10 departments. I will be identifying the top 10 departments with the highest number of orders for later retaining only the orders and products that belong to these top aisles or departments."
      ],
      "metadata": {
        "id": "sc6C635kq_z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_orders_active_users = pd.read_csv('/content/drive/MyDrive/MLOps/Instant_Cart/filtered_orders_active_users.csv')"
      ],
      "metadata": {
        "id": "up4PiuqDvxOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, I am merging aisles.csv and departments.csv with products.csv to enrich the product information with aisle and department details."
      ],
      "metadata": {
        "id": "0YnOCk7sym09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging products with aisles and departments\n",
        "products_enriched = pd.merge(\n",
        "    products,\n",
        "    aisles,\n",
        "    on='aisle_id',\n",
        "    how='left'\n",
        ")\n",
        "products_enriched = pd.merge(\n",
        "    products_enriched,\n",
        "    departments,\n",
        "    on='department_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Verifying the columns in the enriched product dataset\n",
        "print(products_enriched.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju-tjz1auv94",
        "outputId": "c748ffed-334b-4179-da6c-87373a111b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['product_id', 'product_name', 'aisle_id', 'department_id', 'aisle',\n",
            "       'department'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, I joing the enriched products information (products_enriched) with the (filtered_orders_active_users) DataFrame."
      ],
      "metadata": {
        "id": "gVi1xpfwLGF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging product details into the filtered orders dataset\n",
        "filtered_orders_with_details = pd.merge(\n",
        "    filtered_orders_active_users,\n",
        "    products_enriched,\n",
        "    on='product_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Verifying the merged dataset\n",
        "print(filtered_orders_with_details.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDE1Tmmv7a8",
        "outputId": "9c066621-8f53-4abf-9cd1-ed11a9f59734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['order_id', 'product_id', 'add_to_cart_order', 'reordered', 'user_id',\n",
            "       'product_name', 'aisle_id', 'department_id', 'aisle', 'department'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I group the data by aisle and department (separate) and calculate the total number of orders. Then, sorting the results in descending order and retain the top 10."
      ],
      "metadata": {
        "id": "YmSFA836LRaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting orders by aisle\n",
        "aisle_order_counts = filtered_orders_with_details.groupby('aisle').size().reset_index(name='order_count')\n",
        "\n",
        "# Getting the top 10 aisles\n",
        "top_aisles = aisle_order_counts.nlargest(10, 'order_count')\n",
        "top_aisle_names = top_aisles['aisle']\n",
        "\n",
        "print(f\"Top 10 aisles: {list(top_aisle_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV6QwZuvwaNH",
        "outputId": "3a9440f7-e9ff-4582-ae26-993f601f4e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 aisles: ['fresh fruits', 'fresh vegetables', 'packaged vegetables fruits', 'yogurt', 'packaged cheese', 'milk', 'water seltzer sparkling water', 'chips pretzels', 'soy lactosefree', 'bread']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting orders by department\n",
        "department_order_counts = filtered_orders_with_details.groupby('department').size().reset_index(name='order_count')\n",
        "\n",
        "# Getting the top 10 departments\n",
        "top_departments = department_order_counts.nlargest(10, 'order_count')\n",
        "top_department_names = top_departments['department']\n",
        "\n",
        "print(f\"Top 10 departments: {list(top_department_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdIUz83AweLD",
        "outputId": "b1430fdb-427f-424d-dd26-d25aed96bf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 departments: ['produce', 'dairy eggs', 'snacks', 'beverages', 'frozen', 'pantry', 'bakery', 'deli', 'canned goods', 'dry goods pasta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering orders for top aisles\n",
        "filtered_by_aisles = filtered_orders_with_details[filtered_orders_with_details['aisle'].isin(top_aisle_names)]\n",
        "\n",
        "print(f\"Remaining orders after filtering by top aisles: {len(filtered_by_aisles)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IPEfXobwhOm",
        "outputId": "3d8aab3e-6d8a-4047-b918-c19ebf708bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining orders after filtering by top aisles: 14096649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering orders for top departments\n",
        "filtered_by_departments = filtered_orders_with_details[filtered_orders_with_details['department'].isin(top_department_names)]\n",
        "\n",
        "print(f\"Remaining orders after filtering by top departments: {len(filtered_by_departments)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F35nwG4Gwmp7",
        "outputId": "0e2c3a4f-67e6-4927-8948-5615322c5309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remaining orders after filtering by top departments: 25702383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying aisles or departments in the filtered dataset\n",
        "print(filtered_by_aisles['aisle'].value_counts())\n",
        "print(filtered_by_departments['department'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRNxqET6wsP4",
        "outputId": "1d42f96a-e2cf-4acf-e404-6516ef1d81b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aisle\n",
            "fresh fruits                     3485989\n",
            "fresh vegetables                 3378122\n",
            "packaged vegetables fruits       1686448\n",
            "yogurt                           1364214\n",
            "packaged cheese                   905963\n",
            "milk                              806036\n",
            "water seltzer sparkling water     720034\n",
            "chips pretzels                    635021\n",
            "soy lactosefree                   587908\n",
            "bread                             526914\n",
            "Name: count, dtype: int64\n",
            "department\n",
            "produce            9133122\n",
            "dairy eggs         4988600\n",
            "snacks             2366457\n",
            "beverages          2168493\n",
            "frozen             1888991\n",
            "pantry             1502823\n",
            "bakery             1042682\n",
            "deli                940087\n",
            "canned goods        928885\n",
            "dry goods pasta     742243\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to filter the data by \"Top 10 Departments\" for the following reasons:\n",
        "\n",
        "- It aligns with the project's goal of creatinga resuable ML pipeline, as department-level insights generalize better.\n",
        "- Provides a broader perspective, covering diverse products and trends.\n",
        "- Reduces the dataset size efficiently while retaining valuable data for high-level analysis.\n",
        "\n",
        "Next, I filter the dataset by the top 10 departments: produce, dairy eggs, snacks, etc. Then, I save the filtered dataset into .csv format."
      ],
      "metadata": {
        "id": "KRnHPZ9XL3SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the files\n",
        "output_path = \"/content/drive/MyDrive/MLOps/Instant_Cart/filtered_by_top_departments.csv\"  # Desired output path\n",
        "\n",
        "# Top 10 departments\n",
        "top_departments = [\n",
        "    \"produce\", \"dairy eggs\", \"snacks\", \"beverages\", \"frozen\",\n",
        "    \"pantry\", \"bakery\", \"deli\", \"canned goods\", \"dry goods pasta\"\n",
        "]\n",
        "\n",
        "# Filtering the dataset to include only top departments\n",
        "filtered_by_departments = filtered_orders_with_details[\n",
        "    filtered_orders_with_details['department'].isin(top_departments)\n",
        "]\n",
        "\n",
        "# Saving the filtered dataset\n",
        "filtered_by_departments.to_csv(output_path, index=False)\n",
        "\n",
        "# Summary of the filtered dataset\n",
        "filtered_summary = {\n",
        "    \"Remaining Rows\": len(filtered_by_departments),\n",
        "    \"Unique Orders\": filtered_by_departments['order_id'].nunique(),\n",
        "    \"Unique Users\": filtered_by_departments['user_id'].nunique(),\n",
        "    \"Unique Departments\": filtered_by_departments['department'].nunique()\n",
        "}\n",
        "\n",
        "print(\"Filtered dataset saved successfully.\")\n",
        "print(filtered_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC7lRwTvx5mc",
        "outputId": "f6e4f958-7493-49b0-e14a-727b90bd38b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved successfully.\n",
            "{'Remaining Rows': 25702383, 'Unique Orders': 2389985, 'Unique Users': 184304, 'Unique Departments': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further filtering rarely reordered products\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "judCA0QHKyVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the previous filtering process, we obtained a total number of unique orders of: 2,389,985. Now, I will proceed to calculate the reorder rate for each product by grouping the data by product_id and taking the mean of the \"reordered\" column."
      ],
      "metadata": {
        "id": "-HqT1ZsfMkca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the filtered dataset\n",
        "filtered_by_top_departments_path = \"/content/drive/MyDrive/MLOps/Instant_Cart/filtered_by_top_departments.csv\"\n",
        "filtered_by_top_departments = pd.read_csv(filtered_by_top_departments_path)\n",
        "\n",
        "# Calculating reorder rate for each product\n",
        "product_reorder_rate = filtered_by_top_departments.groupby('product_id')['reordered'].mean().reset_index()\n",
        "product_reorder_rate.rename(columns={'reordered': 'reorder_rate'}, inplace=True)\n",
        "\n",
        "# Setting a threshold for rarely reordered products (e.g., 0.2 or 20%)\n",
        "threshold = 0.2\n",
        "frequently_reordered_products = product_reorder_rate[product_reorder_rate['reorder_rate'] > threshold]\n",
        "\n",
        "print(f\"Products with a reorder rate above {threshold}: {len(frequently_reordered_products)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0Lz4UdMj_B",
        "outputId": "9fa7487f-8f29-4d3d-aeb9-a8be16da398e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products with a reorder rate above 0.2: 8002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the dataset to include only frequently reordered products\n",
        "filtered_frequent_reorders = filtered_by_top_departments[\n",
        "    filtered_by_top_departments['product_id'].isin(frequently_reordered_products['product_id'])\n",
        "]\n",
        "\n",
        "print(f\"Filtered dataset to include frequently reordered products.\")\n",
        "print(f\"Remaining Rows: {len(filtered_frequent_reorders)}\")\n",
        "print(f\"Unique Orders: {filtered_frequent_reorders['order_id'].nunique()}\")\n",
        "print(f\"Unique Products: {filtered_frequent_reorders['product_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0P6_HJ6NiWc",
        "outputId": "3b4b5056-9b51-451c-9846-17c478139c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset to include frequently reordered products.\n",
            "Remaining Rows: 25454061\n",
            "Unique Orders: 2389931\n",
            "Unique Products: 8002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the filtered dataset\n",
        "output_path_frequent_reorders = \"/content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_reorders.csv\"\n",
        "filtered_frequent_reorders.to_csv(output_path_frequent_reorders, index=False)\n",
        "\n",
        "print(f\"Filtered dataset saved at {output_path_frequent_reorders}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS7OxgJaN58g",
        "outputId": "731d7065-2994-4390-adf8-a608a8afde0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved at /content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_reorders.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering for frequent buyer"
      ],
      "metadata": {
        "id": "shv4TREbPvH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the previous result, the dataset was only reduced to: 2,389,931 orders. Next, I am filtering by identifying frequent buyey. For example: retain users who order top products at least N times."
      ],
      "metadata": {
        "id": "eJGqQmQvPzSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N = 450.\n",
        "This first dataset will be balanced between most frequent buyers and non active users.\n",
        "\n",
        "**Note to consider:**\n",
        "\n",
        "As we increase \"N\", the focus is only on the most active users, which may bias the model toward frequent buyes and their behavior.\n",
        "\n",
        "The model might become less generalize to users with lower purchasing activity.\n",
        "\n",
        "If the dataset is heavily skewed toward a small group of active users, some product-specific might be lost. However, keeping more frequent buyers might still capture sufficient trends highly reordered products.\n",
        "\n",
        "A piperline trained on a subset of frequent buyers may perform for similr groups but may not generalize to less frequent users or broader audience."
      ],
      "metadata": {
        "id": "ogIXoLb6UnGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the threshold for frequent buyers (e.g., at least N = 10 orders)\n",
        "N = 450\n",
        "\n",
        "# Counting the number of orders per user\n",
        "user_order_counts = filtered_frequent_reorders.groupby('user_id').size().reset_index(name='order_count')\n",
        "\n",
        "# Filtering users with at least N orders\n",
        "frequent_buyers = user_order_counts[user_order_counts['order_count'] >= N]\n",
        "frequent_buyer_ids = frequent_buyers['user_id']\n",
        "\n",
        "print(f\"Number of frequent buyers with at least {N} orders: {len(frequent_buyer_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7emFXikfQFIU",
        "outputId": "481672f8-86e4-4308-bc11-3f4acdf7abeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frequent buyers with at least 450 orders: 11033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering orders for frequent buyers\n",
        "filtered_frequent_buyers = filtered_frequent_reorders[\n",
        "    filtered_frequent_reorders['user_id'].isin(frequent_buyer_ids)\n",
        "]\n",
        "\n",
        "print(f\"Filtered dataset to include orders from frequent buyers.\")\n",
        "print(f\"Remaining Rows: {len(filtered_frequent_buyers)}\")\n",
        "print(f\"Unique Orders: {filtered_frequent_buyers['order_id'].nunique()}\")\n",
        "print(f\"Unique Users: {filtered_frequent_buyers['user_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvkBeMymQNak",
        "outputId": "fe7a7179-9959-46d7-b1f2-2cb5d62ddc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset to include orders from frequent buyers.\n",
            "Remaining Rows: 7588145\n",
            "Unique Orders: 562019\n",
            "Unique Users: 11033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the filtered dataset\n",
        "output_path_frequent_buyers = \"/content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_buyers_v1.csv\"\n",
        "filtered_frequent_buyers.to_csv(output_path_frequent_buyers, index=False)\n",
        "\n",
        "print(f\"Filtered dataset saved at {output_path_frequent_buyers}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrqeNICQQTrt",
        "outputId": "2314f3b5-235f-47ba-ca07-b30d91e2ebd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved at /content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_buyers_v1.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N = 850"
      ],
      "metadata": {
        "id": "TnlSYio0U6fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset will be for the less generalize ML model."
      ],
      "metadata": {
        "id": "ti4LMkDaV6Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 850\n",
        "\n",
        "# Counting the number of orders per user\n",
        "user_order_counts = filtered_frequent_reorders.groupby('user_id').size().reset_index(name='order_count')\n",
        "\n",
        "# Filtering users with at least N orders\n",
        "frequent_buyers = user_order_counts[user_order_counts['order_count'] >= N]\n",
        "frequent_buyer_ids = frequent_buyers['user_id']\n",
        "\n",
        "print(f\"Number of frequent buyers with at least {N} orders: {len(frequent_buyer_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsKNz1NUjnF",
        "outputId": "d7ba335e-0879-4975-e6b8-d48a38721f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frequent buyers with at least 850 orders: 2081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering orders for frequent buyers\n",
        "filtered_frequent_buyers = filtered_frequent_reorders[\n",
        "    filtered_frequent_reorders['user_id'].isin(frequent_buyer_ids)\n",
        "]\n",
        "\n",
        "print(f\"Filtered dataset to include orders from frequent buyers.\")\n",
        "print(f\"Remaining Rows: {len(filtered_frequent_buyers)}\")\n",
        "print(f\"Unique Orders: {filtered_frequent_buyers['order_id'].nunique()}\")\n",
        "print(f\"Unique Users: {filtered_frequent_buyers['user_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSRcXreDWBuU",
        "outputId": "dcf6eb9b-6245-4500-a8c8-fecd035181b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset to include orders from frequent buyers.\n",
            "Remaining Rows: 2253205\n",
            "Unique Orders: 137382\n",
            "Unique Users: 2081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the filtered dataset\n",
        "output_path_frequent_buyers = \"/content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_buyers_v2.csv\"\n",
        "filtered_frequent_buyers.to_csv(output_path_frequent_buyers, index=False)\n",
        "\n",
        "print(f\"Filtered dataset saved at {output_path_frequent_buyers}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8DSbzEvWLs9",
        "outputId": "31ae97d3-7b7e-48b0-f754-bf70dcffceea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset saved at /content/drive/MyDrive/MLOps/Instant_Cart/filtered_frequent_buyers_v2.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "gIU6KSSpqvvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "S-aqSNTsrvT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing necessary libraries"
      ],
      "metadata": {
        "id": "h1A2pvinq3Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyathena"
      ],
      "metadata": {
        "id": "wg6KMTJYqwdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awswrangler"
      ],
      "metadata": {
        "id": "pE8Hlbdrq9iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn"
      ],
      "metadata": {
        "id": "zm1jZi0wq-7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyathena import connect"
      ],
      "metadata": {
        "id": "g00zA_qkrA04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import awswrangler as wr\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "s1QDDOYIrEtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "j1OrqsWUrGTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting InstantCart CSV dataset into Parquet"
      ],
      "metadata": {
        "id": "3AeuRQ2HrKPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"s3://sagemaker-us-east-1-209611057751/data-lake/project/filtered_frequent_buyers_v1.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "# Loading CSV from S3\n",
        "\n",
        "train_df, remaining_df = train_test_split(df, train_size=0.4, random_state=42)\n",
        "\n",
        "# Split the remaining data into production and temp datasets (66% production, 33% temp)\n",
        "production_df, temp_df = train_test_split(remaining_df, train_size=0.666666, random_state=42)\n",
        "\n",
        "# Split the temp data into test and validation datasets (50% test, 50% validation)\n",
        "test_df, validation_df = train_test_split(temp_df, train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "oo0-1jHjrNuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining S3 paths\n",
        "parquet_output_path = \"s3://sagemaker-us-east-1-209611057751/data-lake/project/partitioned/\"\n",
        "\n",
        "# Save each split dataset to Parquet with partitioning by 'department'\n",
        "wr.s3.to_parquet(\n",
        "    df=train_df,\n",
        "    path=parquet_output_path + \"train/\",\n",
        "    dataset=True,\n",
        "    mode=\"overwrite\",\n",
        "    partition_cols=[\"department\"],\n",
        "    compression=\"snappy\"\n",
        ")\n",
        "\n",
        "wr.s3.to_parquet(\n",
        "    df=production_df,\n",
        "    path=parquet_output_path + \"production/\",\n",
        "    dataset=True,\n",
        "    mode=\"overwrite\",\n",
        "    partition_cols=[\"department\"],\n",
        "    compression=\"snappy\"\n",
        ")\n",
        "\n",
        "wr.s3.to_parquet(\n",
        "    df=test_df,\n",
        "    path=parquet_output_path + \"test/\",\n",
        "    dataset=True,\n",
        "    mode=\"overwrite\",\n",
        "    partition_cols=[\"department\"],\n",
        "    compression=\"snappy\"\n",
        ")\n",
        "\n",
        "wr.s3.to_parquet(\n",
        "    df=validation_df,\n",
        "    path=parquet_output_path + \"validation/\",\n",
        "    dataset=True,\n",
        "    mode=\"overwrite\",\n",
        "    partition_cols=[\"department\"],\n",
        "    compression=\"snappy\"\n",
        ")"
      ],
      "metadata": {
        "id": "xz9bSD-zrQXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the database if it doesn't exist\n",
        "database_name = \"instacart_db\"\n",
        "try:\n",
        "    # Create the database in AWS Glue\n",
        "    wr.catalog.create_database(name=database_name)\n",
        "    print(f\"Database '{database_name}' created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating database: {e}\")"
      ],
      "metadata": {
        "id": "mwdv_AQLrVm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the Parquet tables in AWS Glue\n",
        "table_name = \"instacart_orders\"\n",
        "\n",
        "wr.catalog.create_parquet_table(\n",
        "    database=database_name,\n",
        "    table=table_name,\n",
        "    path=parquet_output_path + \"train/\",\n",
        "    columns_types={\n",
        "        \"order_id\": \"bigint\",\n",
        "        \"product_id\": \"bigint\",\n",
        "        \"add_to_cart_order\": \"int\",\n",
        "        \"reordered\": \"int\",\n",
        "        \"user_id\": \"bigint\",\n",
        "        \"product_name\": \"string\",\n",
        "        \"aisle_id\": \"int\",\n",
        "        \"department_id\": \"int\",\n",
        "        \"aisle\": \"string\",\n",
        "        \"department\": \"string\"\n",
        "    },\n",
        "    partitions_types={\"department\": \"string\"},\n",
        "    description=\"Partitioned Instacart orders dataset for optimized Athena queries.\"\n",
        ")\n",
        "\n",
        "print(\"Partitioned Parquet table registered in AWS Glue successfully.\")"
      ],
      "metadata": {
        "id": "G-_o0s-HrXkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up Database for InstantCart"
      ],
      "metadata": {
        "id": "NmD2q73mraQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyathena import connect\n",
        "\n",
        "# Defineing AWS Resources\n",
        "bucket_name = \"sagemaker-us-east-1-209611057751\"\n",
        "region = \"us-east-1\"\n",
        "database_name = \"instacart_db\"\n",
        "table_name = \"instacart_orders\"\n",
        "s3_data_location = f\"s3://{bucket_name}/data-lake/project/partitioned/train/\"  # Using partitioned dataset\n",
        "\n",
        "# Defining Athena Staging Directory\n",
        "s3_staging_dir = f\"s3://{bucket_name}/athena/instacart_staging/\"\n",
        "\n",
        "# Creating Athena Connection\n",
        "try:\n",
        "    conn = connect(s3_staging_dir=s3_staging_dir, region_name=region)\n",
        "    cursor = conn.cursor()\n",
        "    print(\"Connected to Athena successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Error connecting to Athena:\", e)\n",
        "\n",
        "# Creating Database\n",
        "create_db_query = f\"CREATE DATABASE IF NOT EXISTS {database_name}\"\n",
        "cursor.execute(create_db_query)\n",
        "print(f\"Database '{database_name}' created successfully!\")\n",
        "\n",
        "# Verifying Database Creation\n",
        "cursor.execute(\"SHOW DATABASES\")\n",
        "databases = [row[0] for row in cursor.fetchall()]\n",
        "if database_name in databases:\n",
        "    print(f\"Database '{database_name}' exists!\")"
      ],
      "metadata": {
        "id": "j3vTWvY7rcMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Athena database"
      ],
      "metadata": {
        "id": "XA5bXf3krgKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_table_query = f\"\"\"\n",
        "CREATE EXTERNAL TABLE IF NOT EXISTS {database_name}.{table_name} (\n",
        "    order_id BIGINT,\n",
        "    product_id BIGINT,\n",
        "    add_to_cart_order INT,\n",
        "    reordered INT,\n",
        "    user_id BIGINT,\n",
        "    product_name STRING,\n",
        "    aisle_id INT,\n",
        "    department_id INT,\n",
        "    aisle STRING\n",
        ")\n",
        "PARTITIONED BY (department STRING)  -- Partitioned by 'department'\n",
        "STORED AS PARQUET\n",
        "LOCATION 's3://sagemaker-us-east-1-209611057751/data-lake/project/partitioned/train/'\n",
        "TBLPROPERTIES ('parquet.compression'='SNAPPY');\n",
        "\"\"\"\n",
        "\n",
        "# Execute Table Creation Query\n",
        "cursor.execute(create_table_query)\n",
        "print(f\"Table '{table_name}' created successfully in database '{database_name}'.\")"
      ],
      "metadata": {
        "id": "DzR3CNRMrh4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running MSCK REPAIR to Load Partitions\n",
        "cursor.execute(f\"MSCK REPAIR TABLE {database_name}.{table_name}\")\n",
        "print(\"Partitions updated successfully.\")"
      ],
      "metadata": {
        "id": "lE8TA4P8rkSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"SHOW DATABASES\")\n",
        "databases = [row[0] for row in cursor.fetchall()]\n",
        "if database_name in databases:\n",
        "    print(f\"Database '{database_name}' exists in Athena!\")\n",
        "else:\n",
        "    print(f\"Database '{database_name}' does not exist.\")"
      ],
      "metadata": {
        "id": "dPB3DFstrmF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running a Sample Query to Verify Data\n",
        "test_query = f\"SELECT count(*) FROM {database_name}.{table_name} ;\"\n",
        "cursor.execute(test_query)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "print(\"Sample Query Results:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "gcewROSOronT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(f\"SHOW PARTITIONS {database_name}.{table_name}\")\n",
        "partitions = cursor.fetchall()\n",
        "if partitions:\n",
        "    print(f\"Partitions found in table '{table_name}': {partitions}\")\n",
        "else:\n",
        "    print(f\"No partitions found in table '{table_name}'.\")"
      ],
      "metadata": {
        "id": "zfFg6kVPrrkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the Total Orders and Unique Users"
      ],
      "metadata": {
        "id": "wW5EG1sDr7Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Query: Total Orders & Unique Users\n",
        "query = f\"\"\"\n",
        "SELECT\n",
        "    COUNT(DISTINCT order_id) AS total_orders,\n",
        "    COUNT(DISTINCT user_id) AS unique_users\n",
        "FROM {database_name}.{table_name};\n",
        "\"\"\"\n",
        "\n",
        "# Executing query\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Printing results\n",
        "print(\"Total Orders & Unique Users:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "8ZcbAdOdr8F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 10 Most Ordered Products"
      ],
      "metadata": {
        "id": "67ArKnz6sC_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "SELECT product_name, COUNT(*) AS total_orders\n",
        "FROM {database_name}.{table_name}\n",
        "GROUP BY product_name\n",
        "ORDER BY total_orders DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "print(\"Top 10 Most Ordered Products:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "6va4eGiWsEuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "#  Bar Chart: Top 10 Most Ordered Products\n",
        "# ===========================\n",
        "\n",
        "products = [\"Banana\", \"Bag of Organic Bananas\", \"Organic Strawberries\", \"Organic Hass Avocado\",\n",
        "            \"Organic Baby Spinach\", \"Organic Raspberries\", \"Organic Avocado\", \"Organic Whole Milk\",\n",
        "            \"Limes\", \"Large Lemon\"]\n",
        "total_orders = [52073, 46964, 39311, 31555, 29459, 21479, 19582, 19211, 17136, 16719]\n",
        "\n",
        "# Creating DataFrame\n",
        "df_products = pd.DataFrame({\"Product Name\": products, \"Total Orders\": total_orders})\n",
        "\n",
        "# Plotting Bar Chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Total Orders\", y=\"Product Name\", data=df_products, palette=\"viridis\")\n",
        "plt.xlabel(\"Total Orders\")\n",
        "plt.ylabel(\"Product Name\")\n",
        "plt.title(\"Top 10 Most Ordered Products\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pEXLa2ILsHsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights"
      ],
      "metadata": {
        "id": "YRbd3XiisRZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall it can be seen that perishable products are the most ordered products and generally follow a trend of the quicker the product spoils the more often it is ordered. This makes sense as the customers most likely are making smaller orders of those products so as to not let them spoil by having them sit on their counters or refrigerators for an extended period of time. A condensed list of some notable findings can be seen in the list below:\n",
        "\n",
        "*   Bananas are the most ordered item with 52073 orders.\n",
        "*   Organic produce is extremely popular making up 7 out of 10 most ordered items.\n",
        "*   Fruits and vegitables make up 9 out of the top 10 most ordered items.\n",
        "*   All of the top 10 items spoil within a matter of weeks after opening."
      ],
      "metadata": {
        "id": "5zZVSafdsK9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reorder Rate per Product"
      ],
      "metadata": {
        "id": "a8xGtdDGu36R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "SELECT\n",
        "    product_name,\n",
        "    COUNT(*) AS total_orders,\n",
        "    SUM(reordered) AS total_reorders,\n",
        "    ROUND(100.0 * SUM(reordered) / COUNT(*), 2) AS reorder_rate\n",
        "FROM {database_name}.{table_name}\n",
        "GROUP BY product_name\n",
        "ORDER BY reorder_rate DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "print(\"Top 10 Products with Highest Reorder Rate:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "E34znjAsu8P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights for Top 10 Products with Highest Reorder Rate:"
      ],
      "metadata": {
        "id": "xNVec_EOu_JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is notable that all of the most reordered items have a 100% reorder rate, indicating that customers who order those items have a strong preference for them specifically. Additional insights as they relate to each product can be seen below:\n",
        "*   **Thirst Quencher Caffeine-Free Naturally Flavored Citrus Soda** and **Smoked Whitefish Salad** have the highest reorder frequency, highlighting that these items are consistently chosen by customers who keep coming back for more.\n",
        "*   **100% Lactose-Free Milk** has a **100% reorder rate**, indicating it is a highly demanded product among lactose-intolerant customers who consistently reorder it.\n",
        "*   **Seltzer Water** and **Sparkling Water, Bottles** as well as **Premium Lots of Pulp Orange Juice** are all drink product meaning that customers who order these product may have a strong preference when it comes to the types of drinks and the brands that they consume."
      ],
      "metadata": {
        "id": "ptFI2WqVvDmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orders by Department"
      ],
      "metadata": {
        "id": "zTfTbUANzimy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "SELECT department, COUNT(*) AS total_orders\n",
        "FROM {database_name}.{table_name}\n",
        "GROUP BY department\n",
        "ORDER BY total_orders DESC;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "print(\"Orders by Department:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "TuQhzl6HzlLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Bar Chart: Orders by Department\n",
        "# ===========================\n",
        "\n",
        "# Data from previous query (Department, Total Orders)\n",
        "departments = [\"produce\", \"dairy eggs\", \"snacks\", \"beverages\", \"frozen\",\n",
        "               \"pantry\", \"bakery\", \"deli\", \"canned goods\", \"dry goods pasta\"]\n",
        "total_orders = [1116850, 619999, 294213, 234613, 201359, 138924, 127884, 114349, 102416, 84651]\n",
        "\n",
        "# Creating DataFrame\n",
        "df_orders_by_department = pd.DataFrame({\"Department\": departments, \"Total Orders\": total_orders})\n",
        "\n",
        "# Plotting Bar Chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Total Orders\", y=\"Department\", data=df_orders_by_department, palette=\"magma\")\n",
        "plt.xlabel(\"Total Orders\")\n",
        "plt.ylabel(\"Department\")\n",
        "plt.title(\"Total Orders by Department\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VF5uPeq5zpUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights"
      ],
      "metadata": {
        "id": "2EitMZJKzsfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsurprisingly, the departments with the most orders generally follow a trend of items that spoil the fastest while adding in a factor of items that are consumed at the highest frequency. Produce and dairy/eggs are atop the list by a sizable margin, followed by items that are consumed on a mostly daily basis, snacks and beverages. Next, frozen items are consumed regularly, but have a longer shelf life so they do not need to be ordered as often. The rest of the top ten departments are almost all non/less perishable items. The exemption to this is deli, which falls into the previously discussed category of items that are consumed regularly and have a shorter shelf life so they are most likely ordered in smaller batches. Additional insights can be seen below in a listed format:\n",
        "*   Produce is the most ordered department with ~1.11 million orders. This aligns with the earlier Top Ordered Products (bananas, avocados, berries).\n",
        "*   Dairy & Eggs ranks second with 619K orders.\n",
        "*   Snacks are the third most popular category (294K orders).\n",
        "*   Beverages (~234K orders) likely include popular items like bottled water, juices, and coffee some of which were in the most reordered top 10.\n",
        "*   Frozen Foods (~201K orders) suggest customers stock up on frozen essentials."
      ],
      "metadata": {
        "id": "YO_5C9nQzw0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Most Popular Aisles"
      ],
      "metadata": {
        "id": "WXCB8vmA2XRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "SELECT aisle, COUNT(*) AS total_orders\n",
        "FROM {database_name}.{table_name}\n",
        "GROUP BY aisle\n",
        "ORDER BY total_orders DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "print(\"Top 10 Aisles:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "l47ZosCB2cAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Bar Chart: Most Popular Aisles\n",
        "# ===========================\n",
        "\n",
        "# Data from previous query (Aisle, Total Orders)\n",
        "aisles = [\"fresh fruits\", \"fresh vegetables\", \"packaged vegetables fruits\", \"yogurt\",\n",
        "          \"packaged cheese\", \"milk\", \"water seltzer sparkling water\", \"chips pretzels\",\n",
        "          \"soy lactosefree\", \"bread\"]\n",
        "aisle_orders = [450026, 404252, 205492, 184903, 112690, 103953, 78019, 74536, 68786, 65469]\n",
        "\n",
        "# Creating DataFrame\n",
        "df_aisles = pd.DataFrame({\"Aisle\": aisles, \"Total Orders\": aisle_orders})\n",
        "\n",
        "# Plotting Bar Chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=\"Total Orders\", y=\"Aisle\", data=df_aisles, palette=\"coolwarm\")\n",
        "plt.xlabel(\"Total Orders\")\n",
        "plt.ylabel(\"Aisle\")\n",
        "plt.title(\"Top 10 Most Popular Aisles\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O01tVKgc2edB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights"
      ],
      "metadata": {
        "id": "5gIej48U2hYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most popular aisles by total orders reflects much of the same findings that have been shown thus far in the data analysis: those items that are the most perishable are ordered the most often. Aisles that have fresh fruits and vegetables rank the highest by a noticeable amount, followed by packaged fruits and vegetables. Then are the dairy products and a few items that fall into the category of snack foods. Other insights can be seen below:\n",
        "\n",
        "*   Fresh Produce Dominance: Fresh Fruits (450K orders) and Fresh Vegetables (404K orders) are the top two aisles.\n",
        "*   Combined, these two alone account for over 950K orders, which reinforces that Produce is the top department.\n",
        "*   Dairy is Highly Popular: Yogurt (184K orders) and Packaged Cheese (112K orders) show strong demand with the addition of Milk (103K orders) confirms that dairy products are household essentials and ordered regularly.\n",
        "* Beverages have high order numbers: Water, Seltzer, and Sparkling Water (78K orders) ranks #7, showing strong demand for bottled drinks.\n",
        "*   Snacks & Bread are Key Pantry Items: Chips & Pretzels (74K orders) are among the most frequently purchased snacks. While Bread (65K orders) is typically a staple food.\n",
        "*   Plant-Based Alternatives: Soy & Lactose-Free Products (68K orders) indicate consumers with dietary restrictions order items that comply with their diet often."
      ],
      "metadata": {
        "id": "K3M0S_1J2kWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reorder Ratio by Department"
      ],
      "metadata": {
        "id": "UZvpnYpK5Udd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "SELECT\n",
        "    department,\n",
        "    COUNT(*) AS total_orders,\n",
        "    SUM(reordered) AS total_reorders,\n",
        "    ROUND(100.0 * SUM(reordered) / COUNT(*), 2) AS reorder_ratio\n",
        "FROM {database_name}.{table_name}\n",
        "GROUP BY department\n",
        "ORDER BY reorder_ratio DESC;\n",
        "\"\"\"\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "print(\"Reorder Ratio by Department:\")\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "U7RctP8C5Ysf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insights"
      ],
      "metadata": {
        "id": "GopYRy205qRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much of the information from the reorder rate by department reflects the trends in the other categories explored so far. The small exception is that beverages and dairy/eggs rank higher on the list than produce. This may be caused by specific preferences in the type of dairy products and beverages as opposed to produce, which may have a higher variance order to order from the same customer. The other departments show bread, deli and snack products are reordered often which aligns with the information that has been gathered with regards to the trend of items that are consumed frequently. Finally, items that have a longer shelf life are reordered less often, possibly indicating that there may be more bulk ordering of these items and there could be orders where these items are not ordered or skipped. Other specifics about the reorder ratio by department can be seen below:\n",
        "\n",
        "*   Dairy & Eggs Have the Highest Reorder Rate (82.73%)\n",
        "*   Beverages Rank #2 in Reorders (80.85%)\n",
        "*   Produce Has a High Reorder Rate (80.71%)\n",
        "*   Bakery (80.43%) & Deli (78.53%) Show Strong Reorder Loyalty\n",
        "*   Snacks & Frozen Foods Have Moderate Reorder Rates (~70%)\n",
        "*   Canned Goods & Dry Goods Have Lower Reorder Rates (~65%)\n",
        "*   Pantry Has the Lowest Reorder Rate (57.26%)"
      ],
      "metadata": {
        "id": "qs0NP5Pw5s0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Pie Chart: Reorder Ratio by Department\n",
        "# ===========================\n",
        "\n",
        "# Data from previous query (Department, Reorder Ratio)\n",
        "departments = [\"dairy eggs\", \"beverages\", \"produce\", \"bakery\", \"deli\",\n",
        "               \"snacks\", \"frozen\", \"canned goods\", \"dry goods pasta\", \"pantry\"]\n",
        "reorder_ratio = [82.73, 80.85, 80.71, 80.43, 78.53, 74.01, 71.87, 65.51, 65.33, 57.26]\n",
        "\n",
        "# Create DataFrame\n",
        "df_departments = pd.DataFrame({\"Department\": departments, \"Reorder Ratio\": reorder_ratio})\n",
        "\n",
        "# Plot Pie Chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(df_departments[\"Reorder Ratio\"], labels=df_departments[\"Department\"],\n",
        "        autopct=\"%1.1f%%\", colors=sns.color_palette(\"viridis\", len(departments)), startangle=140)\n",
        "plt.title(\"Reorder Ratio by Department\")\n",
        "plt.axis(\"equal\")  # Equal aspect ratio ensures the pie is drawn as a circle\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "naBBcABT8oMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Stacked Bar Chart: Reordered vs Non-Reordered Orders by Department\n",
        "# ===========================\n",
        "\n",
        "# Data from previous query (Department, Reordered Orders)\n",
        "departments = [\"dairy eggs\", \"beverages\", \"produce\", \"bakery\", \"deli\",\n",
        "               \"snacks\", \"frozen\", \"canned goods\", \"dry goods pasta\", \"pantry\"]\n",
        "total_orders = [619999, 234613, 1116850, 127884, 114349, 294213, 201359, 102416, 84651, 138924]\n",
        "reordered = [512956, 189692, 901358, 102853, 89802, 217758, 144719, 67094, 55299, 79541]\n",
        "non_reordered = [total - reorder for total, reorder in zip(total_orders, reordered)]\n",
        "\n",
        "# Create DataFrame\n",
        "df_reorders = pd.DataFrame({\"Department\": departments, \"Reordered\": reordered, \"Non-Reordered\": non_reordered})\n",
        "\n",
        "# Plot Stacked Bar Chart (Reordered vs Non-Reordered)\n",
        "df_reorders.set_index(\"Department\")[[\"Reordered\", \"Non-Reordered\"]].plot(kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\")\n",
        "plt.xlabel(\"Department\")\n",
        "plt.ylabel(\"Number of Orders\")\n",
        "plt.title(\"Reordered vs Non-Reordered Orders by Department\")\n",
        "plt.legend([\"Reordered\", \"Non-Reordered\"])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HrZqse9A8tWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for reordered vs non-reordered orders by department:"
      ],
      "metadata": {
        "id": "i4gzNJc69hLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the items reordered or not by department shows the same trends that have been seen throughout the entire expository data analysis. Produce and dairy/eggs have the highest reorder rate with the snacks, beverages and frozen goods departments all ranking similarly to each other. Additionally pantry, canned goods and dry pasta goods reinforce the trend of a reordering of frequently consumed non-perishable goods."
      ],
      "metadata": {
        "id": "NpKi7eB-8v-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Analysis"
      ],
      "metadata": {
        "id": "lqDgolaG805j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data: Numerical Features for Correlation Analysis\n",
        "departments = [\"dairy eggs\", \"beverages\", \"produce\", \"bakery\", \"deli\",\n",
        "               \"snacks\", \"frozen\", \"canned goods\", \"dry goods pasta\", \"pantry\"]\n",
        "total_orders = [619999, 234613, 1116850, 127884, 114349, 294213, 201359, 102416, 84651, 138924]\n",
        "reordered = [512956, 189692, 901358, 102853, 89802, 217758, 144719, 67094, 55299, 79541]\n",
        "reorder_ratio = [82.73, 80.85, 80.71, 80.43, 78.53, 74.01, 71.87, 65.51, 65.33, 57.26]\n",
        "\n",
        "# Creating DataFrame\n",
        "df_correlation = pd.DataFrame({\n",
        "    \"Total Orders\": total_orders,\n",
        "    \"Reordered Orders\": reordered,\n",
        "    \"Reorder Ratio (%)\": reorder_ratio\n",
        "})\n",
        "\n",
        "# Computing Correlation Matrix\n",
        "correlation_matrix = df_correlation.corr()\n",
        "\n",
        "# Plotting Correlation Heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix of Order Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_uFjPYe082-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The correlation matix need to be redone with departments added"
      ],
      "metadata": {
        "id": "laJNy2PH-i7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA summary"
      ],
      "metadata": {
        "id": "QTzt3RGW_WcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Reorder Ratio: strongly correlated with reorders.\n",
        "2. Total Orders: high correlation with reorder likelihood.\n",
        "3. User Reorder percerntage: Helps preduct if a user is likely to reorder.\n",
        "4. Product Popularity: popular items have higher reorders.\n",
        "5. Department and Aisle reorder ratios: certain categories drive higher reorders"
      ],
      "metadata": {
        "id": "9cdJS318_beD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "sTUsIXWH-rlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For creating ML Feature features, the following labels will be made:\n",
        "*   User ID: This tracks individual purchase behavior.\n",
        "*   Product ID: Helps identify frequently reordered products.\n",
        "*   Department ID: Some departments have higher reorder rates.\n",
        "*   Aisle ID: Aisle-level trends impact reorder likelihood.\n",
        "*   Total Orders: Highly correlated with reorder behavior.\n",
        "*   Reorder Ratio: Strong predictor of repeat purchases.\n",
        "*   Total items in Orders: Determines if larger orders influence reorders.\n",
        "*   User Order Frequency: Identifies frequent vs. occasional buyers.\n",
        "*   User Reorder Percentage: Determines likelihood of repeat purchases.\n",
        "*   Product popularity: Captures demand for the product.\n",
        "*   Department reorder ratio: Some departments have stronger reorder trends.\n",
        "*   Aisle Reorder ratio: Aisle-specific reorder behavior.\n",
        "*   Product Reorder trend: Helps detect seasonal or trending products."
      ],
      "metadata": {
        "id": "JCalS_b0-x3m"
      }
    }
  ]
}